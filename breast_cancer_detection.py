# -*- coding: utf-8 -*-
"""Breast_Cancer_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VofCON3soDhkjLe_RV7GG2uCrWc1wGhK

Data Preprocessing :-

1.   Importing the libraries
2.   Importing the dataset
3.   Separated dataset into Independent variables && dependent variables
4.   Data information
5.   More Info Data
6.   Visualize the number of missing
7.   Taking care of missing data
8.   Encoding categorical data
9.   Variance in data
10.   Covariance in data
11.   Correlation in data
12.  Feature Selection
13.  Feature Scaling
14.  Splitting the dataset into the Training set and Test set

**Importing the libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""**Importing the dataset**"""

from google.colab import files
uploaded=files.upload()

import io
dataset=pd.read_csv(io.BytesIO(uploaded['datasets_180_408_data.csv']))
print('Dataset Shape : ',dataset.shape)
print('Dataset : \n',dataset.head(10))
print('Columns Names')
for col in dataset.columns:
  print('Columns :',col)

"""**Separated dataset into Independent variables && dependent variables**"""

X=dataset.iloc[:,2:].values
y=dataset.iloc[:,1:2].values
print('X : \n',X)
print('X Shape : ',X.shape)
print('X Columns')
print('y :\n',y)
print('y shape : ',y.shape)

"""**Draw data information**"""

y = dataset.diagnosis  
print(y)                        # M or B

import seaborn as sns
ax = sns.countplot(y,label="Count")      
B, M = y.value_counts()
print('Number of Benign: ',B)
print('Number of Malignant : ',M)

"""**More Info Data**"""

positive = dataset[dataset['diagnosis'].isin(['M'])]
negative = dataset[dataset['diagnosis'].isin(['B'])]

print('Positive \n ',positive)
print('Negative \n ',negative)

"""**Visualize the number of missing**"""

import missingno as msno 
# Visualize the number of missing 
# values as a bar chart 
msno.bar(dataset)
#msno.matrix(dataset)

"""**Taking care of missing data**"""

from sklearn.impute import SimpleImputer
imputer=SimpleImputer(missing_values=np.nan,strategy='mean')
imputer.fit(X)
X=imputer.transform(X)
print(X)

"""**Encoding categorical data**"""

from sklearn.preprocessing import LabelEncoder
le_y=LabelEncoder()
y=le_y.fit_transform(y)
print(y)

#variance in data
dataset.var()

#covariance in data
dataset.cov()

dataset.corr()

sns.heatmap(dataset.corr())
plt.show()

sns.pairplot(dataset)

"""**Feature Selection**"""

from sklearn.feature_selection import SelectPercentile
from sklearn.feature_selection import chi2 , f_classif 
print('Original X Shape is ' , X.shape)
FeatureSelection = SelectPercentile(score_func = chi2, percentile=85) # score_func can = f_classif
X = FeatureSelection.fit_transform(X, y)

#showing X Dimension 
print('X Shape is ' , X.shape)
print('Selected Features are : ' , FeatureSelection.get_support())

"""**Feature Scaling**"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=sc.fit_transform(X)
print(X)
print(X.shape)

"""**Splitting the dataset into the Training set and Test set**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)
print('X_Train')
print(X_train)
print('****************************')
print('X_test')
print(X_test)
print(X_test.shape)
print('****************************')
print('Y_train')
print(y_train)
print('****************************')
print('Y_test')
print(y_test)

"""Algorithm Used:-

1.   Logistic Regression
      1. Confusion Matrix
      2. F1 Score
      3. Recall Score Score (Sensitivity)
      4. Precision Score (Specificity)
      5. ROC Curve

2.   K Nearest Neighbors [ KNN ]
      1. Confusion Matrix
      2. F1 Score
      3. Recall Score Score (Sensitivity)
      4. Precision Score (Specificity)
      5. ROC Curve

3.   Support Vector Machine Algorithm [ SVM ]
      1. Confusion Matrix
      2. F1 Score
      3. Recall Score Score (Sensitivity)
      4. Precision Score (Specificity)
      5. ROC Curve

4.   Decision Tree Algorithm
      1. Confusion Matrix
      2. F1 Score
      3. Recall Score Score (Sensitivity)
      4. Precision Score (Specificity)
      5. ROC Curve

5.   Random Forest Algorithm
      1. Confusion Matrix
      2. F1 Score
      3. Recall Score Score (Sensitivity)
      4. Precision Score (Specificity)
      5. ROC Curve

6.   Naive Bayes
      1. Confusion Matrix
      2. Classification Report
      3. Precision Recall F1score Support
      5. ROC Curve

**Logistic Regression Algorithm**
"""

from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression(random_state=0)
classifier.fit(X_train,y_train)
print('LogisticRegression Train Score is : ' , classifier.score(X_train, y_train))
print('LogisticRegression Test Score is : ' , classifier.score(X_test, y_test))

y_pred=classifier.predict(X_test)
print('Y Test')
print(y_test)
print('Y predicted')
print(y_pred)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(accuracy_score(y_test, y_pred))
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

"""**F1 Score**"""

#Import Libraries
from sklearn.metrics import f1_score
#----------------------------------------------------

#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)
# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

F1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples
print('F1 Score is : ', F1Score)

"""**Recall Score Score (Sensitivity)**"""

#Import Libraries
from sklearn.metrics import recall_score
#----------------------------------------------------
#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  
# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

RecallScore = recall_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples
print('Recall Score is : ', RecallScore)

"""**Precision Score (Specificity)**"""

#Import Libraries
from sklearn.metrics import precision_score
#----------------------------------------------------

#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  
# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)

PrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples
print('Precision Score is : ', PrecisionScore)

"""**ROC Curve**"""

#Import Libraries
from sklearn.metrics import roc_curve
#----------------------------------------------------

#Calculating Receiver Operating Characteristic :  
#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)

fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred)
print('fpr Value  : ', fprValue)
print('tpr Value  : ', tprValue)
print('thresholds Value  : ', thresholdsValue)

"""**Support Vector Machine Algorithm [S V M]**"""

from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf', random_state = 1)
classifier.fit(X_train, y_train)
print('LogisticRegression Train Score is : ' , classifier.score(X_train, y_train))
print('LogisticRegression Test Score is : ' , classifier.score(X_test, y_test))

y_pred2=classifier.predict(X_test)
print('Y Test')
print(y_test)
print('Y predicted2')
print(y_pred2)
print(np.concatenate((y_pred2.reshape(len(y_pred2),1), y_test.reshape(len(y_test),1)),1))

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred2)
print(cm)
accuracy_score(y_test, y_pred2)
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

"""**F1 Score**"""

#Import Libraries
from sklearn.metrics import f1_score
#----------------------------------------------------

#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)
# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

F1Score = f1_score(y_test, y_pred2, average='micro') #it can be : binary,macro,weighted,samples
print('F1 Score is : ', F1Score)

"""**Recall Score Score (Sensitivity)**"""

#Import Libraries
from sklearn.metrics import recall_score
#----------------------------------------------------
#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  
# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

RecallScore = recall_score(y_test, y_pred2, average='micro') #it can be : binary,macro,weighted,samples
print('Recall Score is : ', RecallScore)

"""**Precision Score (Specificity)**"""

#Import Libraries
from sklearn.metrics import precision_score
#----------------------------------------------------

#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  
# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)

PrecisionScore = precision_score(y_test, y_pred2, average='micro') #it can be : binary,macro,weighted,samples
print('Precision Score is : ', PrecisionScore)

"""**ROC Curve**"""

#Import Libraries
from sklearn.metrics import roc_curve
#----------------------------------------------------

#Calculating Receiver Operating Characteristic :  
#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)

fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred2)
print('fpr Value  : ', fprValue)
print('tpr Value  : ', tprValue)
print('thresholds Value  : ', thresholdsValue)

"""**KNN Algorithm**"""

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 13, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)
print('LogisticRegression Train Score is : ' , classifier.score(X_train, y_train))
print('LogisticRegression Test Score is : ' , classifier.score(X_test, y_test))

y_pred3 = classifier.predict(X_test)
print(np.concatenate((y_pred3.reshape(len(y_pred3),1), y_test.reshape(len(y_test),1)),1))

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred3)
print(cm)
print(accuracy_score(y_test, y_pred3))
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

"""**F1 Score**"""

#Import Libraries
from sklearn.metrics import f1_score
#----------------------------------------------------

#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)
# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

F1Score = f1_score(y_test, y_pred3, average='micro') #it can be : binary,macro,weighted,samples
print('F1 Score is : ', F1Score)

"""**Recall Score Score (Sensitivity)**"""

#Import Libraries
from sklearn.metrics import recall_score
#----------------------------------------------------
#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  
# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

RecallScore = recall_score(y_test, y_pred3, average='micro') #it can be : binary,macro,weighted,samples
print('Recall Score is : ', RecallScore)

"""**Precision Score (Specificity)**"""

#Import Libraries
from sklearn.metrics import precision_score
#----------------------------------------------------

#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  
# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)

PrecisionScore = precision_score(y_test, y_pred3, average='micro') #it can be : binary,macro,weighted,samples
print('Precision Score is : ', PrecisionScore)

"""**ROC Curve**"""

#Import Libraries
from sklearn.metrics import roc_curve
#----------------------------------------------------

#Calculating Receiver Operating Characteristic :  
#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)

fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred3)
print('fpr Value  : ', fprValue)
print('tpr Value  : ', tprValue)
print('thresholds Value  : ', thresholdsValue)

"""**Decision Tree Algorithm**"""

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

y_pred4 = classifier.predict(X_test)
print(np.concatenate((y_pred4.reshape(len(y_pred4),1), y_test.reshape(len(y_test),1)),1))

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred4)
print(cm)
print(accuracy_score(y_test, y_pred4))
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

"""**F1 Score**"""

#Import Libraries
from sklearn.metrics import f1_score
#----------------------------------------------------

#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)
# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

F1Score = f1_score(y_test, y_pred4, average='micro') #it can be : binary,macro,weighted,samples
print('F1 Score is : ', F1Score)

"""**Recall Score Score (Sensitivity)**"""

#Import Libraries
from sklearn.metrics import recall_score
#----------------------------------------------------
#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  
# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

RecallScore = recall_score(y_test, y_pred4, average='micro') #it can be : binary,macro,weighted,samples
print('Recall Score is : ', RecallScore)

"""**Precision Score (Specificity)**"""

#Import Libraries
from sklearn.metrics import precision_score
#----------------------------------------------------

#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  
# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)

PrecisionScore = precision_score(y_test, y_pred4, average='micro') #it can be : binary,macro,weighted,samples
print('Precision Score is : ', PrecisionScore)

"""**ROC Curve**"""

#Import Libraries
from sklearn.metrics import roc_curve
#----------------------------------------------------

#Calculating Receiver Operating Characteristic :  
#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)

fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred4)
print('fpr Value  : ', fprValue)
print('tpr Value  : ', tprValue)
print('thresholds Value  : ', thresholdsValue)

"""**Random Forest Algorithm**"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

y_pred5 = classifier.predict(X_test)
print(np.concatenate((y_pred5.reshape(len(y_pred5),1), y_test.reshape(len(y_test),1)),1))

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred5)
print(cm)
print(accuracy_score(y_test, y_pred5))
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

"""**F1 Score**"""

#Import Libraries
from sklearn.metrics import f1_score
#----------------------------------------------------

#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)
# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

F1Score = f1_score(y_test, y_pred5, average='micro') #it can be : binary,macro,weighted,samples
print('F1 Score is : ', F1Score)

"""**Recall Score Score (Sensitivity)**"""

#Import Libraries
from sklearn.metrics import recall_score
#----------------------------------------------------
#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  
# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)

RecallScore = recall_score(y_test, y_pred5, average='micro') #it can be : binary,macro,weighted,samples
print('Recall Score is : ', RecallScore)

"""**Precision Score (Specificity)**"""

#Import Libraries
from sklearn.metrics import precision_score
#----------------------------------------------------

#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  
# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)

PrecisionScore = precision_score(y_test, y_pred5, average='micro') #it can be : binary,macro,weighted,samples
print('Precision Score is : ', PrecisionScore)

"""**ROC Curve**"""

#Import Libraries
from sklearn.metrics import roc_curve
#----------------------------------------------------

#Calculating Receiver Operating Characteristic :  
#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)

fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred4)
print('fpr Value  : ', fprValue)
print('tpr Value  : ', tprValue)
print('thresholds Value  : ', thresholdsValue)

#Import Libraries
from sklearn.naive_bayes import BernoulliNB
#----------------------------------------------------
#Applying BernoulliNB Model 

'''
#sklearn.naive_bayes.BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True,class_prior=None)
'''

BernoulliNBModel = BernoulliNB(alpha=1.0,binarize=1)
BernoulliNBModel.fit(X_train, y_train)

#Calculating Details
print('BernoulliNBModel Train Score is : ' , BernoulliNBModel.score(X_train, y_train))
print('BernoulliNBModel Test Score is : ' , BernoulliNBModel.score(X_test, y_test))
print('----------------------------------------------------')

#Calculating Prediction
y_pred6 = BernoulliNBModel.predict(X_test)
y_pred_prob = BernoulliNBModel.predict_proba(X_test)
y_pred_prob2=y_pred_prob.astype(int)
print('Predicted Value for BernoulliNBModel is : ' , y_pred6)
print('Prediction Probabilities Value for BernoulliNBModel is : \n' , y_pred_prob2)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred6)
print(cm)
print(accuracy_score(y_test, y_pred6))
# drawing confusion matrix
sns.heatmap(cm, center = True)
plt.show()

#Import Libraries
from sklearn.metrics import classification_report
#----------------------------------------------------

#Calculating classification Report :  
#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)

ClassificationReport = classification_report(y_test,y_pred6)
print('Classification Report is : ', ClassificationReport )

#Import Libraries
from sklearn.metrics import precision_recall_fscore_support
#----------------------------------------------------

#Calculating Precision recall Score :  
#metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=
#                                        None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)

PrecisionRecallScore = precision_recall_fscore_support(y_test, y_pred6, average='macro') #it can be : binary,macro,weighted,samples
print('Precision Recall Score is : ', PrecisionRecallScore)